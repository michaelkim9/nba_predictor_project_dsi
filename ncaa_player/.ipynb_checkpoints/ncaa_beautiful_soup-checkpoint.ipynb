{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SoupFromURL(url, suppressOutput=True):\n",
    "\n",
    "    if not suppressOutput:\n",
    "        print(url)\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    return BeautifulSoup(r.text, \"html5lib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping player page for stats\n",
    "\n",
    "The function below scrapes any given player url page for stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ncaa_stats_dict(url):\n",
    "    player_page = SoupFromURL(str(url))\n",
    "    \n",
    "    #player profile info\n",
    "    a = player_page.find_all('div', attrs={'class':'nothumb'})[0]\n",
    "    a_soup = BeautifulSoup(str(a),\"html5lib\")\n",
    "    a = player_page.find_all('div', attrs={'class':'nothumb'})[0]\n",
    "    \n",
    "    try:\n",
    "        n = str(a_soup.text.split('\\n')[1])\n",
    "        name = n.replace(\"\\t\",\"\")\n",
    "    except:\n",
    "        name = None\n",
    "    \n",
    "    try:\n",
    "        p = str(a_soup.text.split('\\n')[13])\n",
    "        position = p.replace(\"  \",\"\")\n",
    "    except:\n",
    "        position = None\n",
    "    \n",
    "    try:\n",
    "        ft = float(str(a_soup.text.split('\\n')[17])[2])*12\n",
    "        inch = float(str(a_soup.text.split('\\n')[17])[4])\n",
    "        height = ft+inch\n",
    "    except:\n",
    "        height = None\n",
    "    \n",
    "    try:\n",
    "        weight = str(a_soup.text.split('\\n')[17])[7:12]\n",
    "        weight = re.sub('[^0-9]','', weight)\n",
    "    except:\n",
    "        weight = None\n",
    "    \n",
    "    ### high school\n",
    "    hs_list = []\n",
    "    try:\n",
    "        hs = str(a_soup.text.split('\\n')[22])\n",
    "        high_school = hs.replace(\"  High School: \",\"\")\n",
    "        hs_list.append(high_school)\n",
    "    \n",
    "        hs_2 = str(a_soup.text.split('\\n')[26])\n",
    "        high_school_2 = hs_2.replace(\"  High School: \",\"\")\n",
    "        hs_list.append(high_school_2)\n",
    "        \n",
    "        hs_list = [x for x in hs_list if not '  ' in x]\n",
    "        hs_list.append(None)\n",
    "    except:\n",
    "        hs_list.append(None)\n",
    "    \n",
    "    while '' in hs_list:\n",
    "        hs_list.remove('')\n",
    "        \n",
    "    ### college\n",
    "    col_list = []\n",
    "    try:\n",
    "        c_4 = str(a_soup.text.split('\\n')[18])\n",
    "        college_4 = c_4.replace(\"  School: \",\"\")\n",
    "        college_4 = college_4.replace(\"  Schools: \",\"\")\n",
    "        col_list.append(college_4)\n",
    "    \n",
    "        c = str(a_soup.text.split('\\n')[28])\n",
    "        college = c.replace(\"  School: \",\"\")\n",
    "        college = college.replace(\"  Schools: \",\"\")\n",
    "        col_list.append(college)\n",
    "    \n",
    "        c_2 = str(a_soup.text.split('\\n')[32])\n",
    "        college_2 = c_2.replace(\"  School: \",\"\")\n",
    "        college_2 = college_2.replace(\"  Schools: \",\"\")\n",
    "        col_list.append(college_2)\n",
    "    \n",
    "        c_3 = str(a_soup.text.split('\\n')[24])\n",
    "        college_3 = c_3.replace(\"  School: \",\"\")\n",
    "        college_3 = college_3.replace(\"  Schools: \",\"\")\n",
    "        col_list.append(college_3)\n",
    "\n",
    "        col_list = [x for x in col_list if not '  ' in x]\n",
    "        col_list.append(None)\n",
    "    except:\n",
    "        col_list.append(None)\n",
    "\n",
    "    while '' in col_list:\n",
    "        col_list.remove('')\n",
    "    \n",
    "    #player stats\n",
    "    stat_list = []\n",
    "    try:\n",
    "        p = player_page.find_all('div', attrs={'class':'stats_pullout'})[0]\n",
    "        p_soup = BeautifulSoup(str(p),\"html5lib\")\n",
    "        stat = p_soup.text.split('\\n')[1::4][2:]\n",
    "    \n",
    "        #stat_list = []\n",
    "        for s in stat:\n",
    "            try:\n",
    "                if s == str(\"\"):\n",
    "                    stat_list.append(None)\n",
    "                else:\n",
    "                    stat_list.append(float(s))\n",
    "            except:\n",
    "                stat_list.append(None)\n",
    "    except:\n",
    "        stat_list.extend([None,None,None,None,None,None,None,None,None,None])\n",
    "    \n",
    "    #season count and draft year\n",
    "    season_count = player_page.find_all('div', attrs={'class':'overthrow table_container'})[0]\n",
    "    season_count_soup = BeautifulSoup(str(season_count),\"html5lib\")\n",
    "    season_count = season_count_soup.text.split('\\n')\n",
    "    season_count = season_count[33:37]\n",
    "    season_count = [x for x in season_count if not 'Career' in x]\n",
    "    season_count = [x for x in season_count if not '  ' in x]\n",
    "    final_season_count = len(list(filter(None, season_count)))\n",
    "    \n",
    "    draft_year_list = list(filter(None, season_count))\n",
    "    if len(draft_year_list) == 4:\n",
    "        final_year = str(draft_year_list[3])[5:7]\n",
    "    elif len(draft_year_list) == 3:\n",
    "        final_year = str(draft_year_list[2])[5:7]\n",
    "    elif len(draft_year_list) == 2:\n",
    "        final_year = str(draft_year_list[1])[5:7]\n",
    "    elif len(draft_year_list) == 1:\n",
    "        final_year = str(draft_year_list[0])[5:7]\n",
    "\n",
    "    if int(final_year[0]) in [0,1]:\n",
    "        final_draft_year = int(final_year) + 2000\n",
    "    elif int(final_year[0]) in [9,8,7,6,5,4,3,2]:\n",
    "        final_draft_year = int(final_year) + 1900\n",
    "    \n",
    "    #creating player dictionary\n",
    "    player_dict = {\n",
    "        'player_name':name,\n",
    "        'position':position,\n",
    "        'height(inches)':height,\n",
    "        'weight(lbs)':weight,\n",
    "        'high_school':hs_list[0],\n",
    "        'college':col_list[0],\n",
    "        'draft_year':final_draft_year,\n",
    "        'years_in_college':final_season_count,\n",
    "        'games':stat_list[0],\n",
    "        'points':stat_list[1],\n",
    "        'rebounds':stat_list[2],\n",
    "        'assists':stat_list[3],\n",
    "        'fg_percent':stat_list[4],\n",
    "        '3_fg_percent':stat_list[5],\n",
    "        'free_throw_percent':stat_list[6],\n",
    "        'effective_fg_percent':stat_list[7],\n",
    "        'player_efficiency_rating':stat_list[8],\n",
    "        'win_shares':stat_list[9]\n",
    "    }\n",
    "    return player_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3_fg_percent': 25.0,\n",
       " 'assists': 0.8,\n",
       " 'college': 'UNC',\n",
       " 'draft_year': 1995,\n",
       " 'effective_fg_percent': 63.6,\n",
       " 'fg_percent': 63.5,\n",
       " 'free_throw_percent': 62.1,\n",
       " 'games': 69.0,\n",
       " 'height(inches)': 73.0,\n",
       " 'high_school': None,\n",
       " 'player_efficiency_rating': None,\n",
       " 'player_name': 'Rasheed Wallace',\n",
       " 'points': 13.0,\n",
       " 'position': 'Forward',\n",
       " 'rebounds': 7.4,\n",
       " 'weight(lbs)': '225',\n",
       " 'win_shares': None,\n",
       " 'years_in_college': 2}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncaa_stats_dict('https://www.sports-reference.com/cbb/players/rasheed-wallace-1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get index page urls\n",
    "\n",
    "I noticed that there is a pattern to the player index page url's on sports-reference. I followed the pattern to get a list of url's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.sports-reference.com/cbb/players/a-index.html',\n",
       " 'https://www.sports-reference.com/cbb/players/b-index.html',\n",
       " 'https://www.sports-reference.com/cbb/players/c-index.html',\n",
       " 'https://www.sports-reference.com/cbb/players/d-index.html',\n",
       " 'https://www.sports-reference.com/cbb/players/e-index.html',\n",
       " 'https://www.sports-reference.com/cbb/players/f-index.html',\n",
       " 'https://www.sports-reference.com/cbb/players/g-index.html',\n",
       " 'https://www.sports-reference.com/cbb/players/h-index.html',\n",
       " 'https://www.sports-reference.com/cbb/players/i-index.html',\n",
       " 'https://www.sports-reference.com/cbb/players/j-index.html',\n",
       " 'https://www.sports-reference.com/cbb/players/k-index.html',\n",
       " 'https://www.sports-reference.com/cbb/players/l-index.html',\n",
       " 'https://www.sports-reference.com/cbb/players/m-index.html',\n",
       " 'https://www.sports-reference.com/cbb/players/n-index.html',\n",
       " 'https://www.sports-reference.com/cbb/players/o-index.html',\n",
       " 'https://www.sports-reference.com/cbb/players/p-index.html',\n",
       " 'https://www.sports-reference.com/cbb/players/q-index.html',\n",
       " 'https://www.sports-reference.com/cbb/players/r-index.html',\n",
       " 'https://www.sports-reference.com/cbb/players/s-index.html',\n",
       " 'https://www.sports-reference.com/cbb/players/t-index.html',\n",
       " 'https://www.sports-reference.com/cbb/players/u-index.html',\n",
       " 'https://www.sports-reference.com/cbb/players/v-index.html',\n",
       " 'https://www.sports-reference.com/cbb/players/w-index.html',\n",
       " 'https://www.sports-reference.com/cbb/players/x-index.html',\n",
       " 'https://www.sports-reference.com/cbb/players/y-index.html',\n",
       " 'https://www.sports-reference.com/cbb/players/z-index.html']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "index_urls = []\n",
    "for letter in string.ascii_lowercase:\n",
    "    letter_page = 'https://www.sports-reference.com/cbb/players/{}-index.html'.format(letter)\n",
    "    index_urls.append(letter_page)\n",
    "\n",
    "index_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get player urls\n",
    "\n",
    "Within each of the index pages, there was a pattern within the HTML code that references all the links on the page. I scraped all the links and discarded the ones that weren't relevant such as the links to schools or other parts of the site that weren't player pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_player_urls(index_url_link):\n",
    "\n",
    "    player_urls = []\n",
    "    index_page = SoupFromURL(index_url_link)\n",
    "    index_names = index_page.find_all('p')\n",
    "    index_soup = BeautifulSoup(str(index_names),\"html5lib\")\n",
    "    links = index_soup('a', href=True)\n",
    "    \n",
    "    for l in links:\n",
    "        try:\n",
    "            player_urls.append('https://www.sports-reference.com' + l.attrs['href'])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    player_urls = [x for x in player_urls if not 'schools' in x]\n",
    "    player_urls.pop()\n",
    "    player_urls.pop()\n",
    "    player_urls.pop()\n",
    "    player_urls.pop()\n",
    "    return player_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.sports-reference.com/cbb/players/jeff-xavier-1.html',\n",
       " 'https://www.sports-reference.com/cbb/players/ioannis-xenakis-1.html',\n",
       " 'https://www.sports-reference.com/cbb/players/aaron-xia-1.html',\n",
       " 'https://www.sports-reference.com/cbb/players/ji-xiang-1.html',\n",
       " 'https://www.sports-reference.com/cbb/players/oliver-xu-1.html',\n",
       " 'https://www.sports-reference.com/cbb/players/tao-xu-1.html']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_player_urls('https://www.sports-reference.com/cbb/players/x-index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Stats Dataframe Of All Players On Index Page\n",
    "\n",
    "Now that I have a function to scrape player pages for their stats and a list of index_urls with a function to get all the page urls, I decided to create another function below where you pass in the index url to generate a dataframe with player stats for all players listed on that page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_player_df(first_letter):\n",
    "    \n",
    "    index_url_link = 'https://www.sports-reference.com/cbb/players/{}-index.html'.format(first_letter)\n",
    "    \n",
    "    player_urls = []\n",
    "    index_page = SoupFromURL(index_url_link)\n",
    "    index_names = index_page.find_all('p')\n",
    "    index_soup = BeautifulSoup(str(index_names),\"html5lib\")\n",
    "    links = index_soup('a', href=True)\n",
    "    \n",
    "    for l in links:\n",
    "        try:\n",
    "            player_urls.append('https://www.sports-reference.com' + l.attrs['href'])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    player_urls = [x for x in player_urls if not 'schools' in x]\n",
    "    player_urls.pop()\n",
    "    player_urls.pop()\n",
    "    player_urls.pop()\n",
    "    player_urls.pop()\n",
    "    \n",
    "    player_stats_list=[]\n",
    "    for url in player_urls:\n",
    "        try:\n",
    "            player_stats_list.append(ncaa_stats_dict(url))\n",
    "            print(url)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    df = pd.DataFrame(player_stats_list)\n",
    "    df = df[[\n",
    "        'player_name',\n",
    "        'position',\n",
    "        'height(inches)',\n",
    "        'weight(lbs)',\n",
    "        'high_school',\n",
    "        'college',\n",
    "        'draft_year',\n",
    "        'years_in_college',\n",
    "        'games',\n",
    "        'points',\n",
    "        'rebounds',\n",
    "        'assists',\n",
    "        'fg_percent',\n",
    "        '3_fg_percent',\n",
    "        'free_throw_percent',\n",
    "        'effective_fg_percent',\n",
    "        'player_efficiency_rating',\n",
    "        'win_shares'\n",
    "    ]]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sports-reference.com/cbb/players/jeff-xavier-1.html\n",
      "https://www.sports-reference.com/cbb/players/ioannis-xenakis-1.html\n",
      "https://www.sports-reference.com/cbb/players/aaron-xia-1.html\n",
      "https://www.sports-reference.com/cbb/players/ji-xiang-1.html\n",
      "https://www.sports-reference.com/cbb/players/oliver-xu-1.html\n",
      "https://www.sports-reference.com/cbb/players/tao-xu-1.html\n"
     ]
    }
   ],
   "source": [
    "x_df = generate_player_df('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>position</th>\n",
       "      <th>height(inches)</th>\n",
       "      <th>weight(lbs)</th>\n",
       "      <th>high_school</th>\n",
       "      <th>college</th>\n",
       "      <th>draft_year</th>\n",
       "      <th>years_in_college</th>\n",
       "      <th>games</th>\n",
       "      <th>points</th>\n",
       "      <th>rebounds</th>\n",
       "      <th>assists</th>\n",
       "      <th>fg_percent</th>\n",
       "      <th>3_fg_percent</th>\n",
       "      <th>free_throw_percent</th>\n",
       "      <th>effective_fg_percent</th>\n",
       "      <th>player_efficiency_rating</th>\n",
       "      <th>win_shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jeff Xavier</td>\n",
       "      <td>Guard</td>\n",
       "      <td>72.0</td>\n",
       "      <td>183</td>\n",
       "      <td>None</td>\n",
       "      <td>Manhattan and Providence</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>124.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>40.8</td>\n",
       "      <td>34.2</td>\n",
       "      <td>78.8</td>\n",
       "      <td>51.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ioannis Xenakis</td>\n",
       "      <td>Center</td>\n",
       "      <td>84.0</td>\n",
       "      <td>213</td>\n",
       "      <td>None</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>2003</td>\n",
       "      <td>2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.8</td>\n",
       "      <td>44.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aaron Xia</td>\n",
       "      <td>Forward</td>\n",
       "      <td>80.0</td>\n",
       "      <td>203</td>\n",
       "      <td>None</td>\n",
       "      <td>Citadel</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>45.7</td>\n",
       "      <td>30.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ji Xiang</td>\n",
       "      <td>Forward</td>\n",
       "      <td>73.0</td>\n",
       "      <td>208</td>\n",
       "      <td>None</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>40.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.6</td>\n",
       "      <td>40.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oliver Xu</td>\n",
       "      <td>Guard</td>\n",
       "      <td>74.0</td>\n",
       "      <td>170</td>\n",
       "      <td>Hong Kong International School</td>\n",
       "      <td>Rice</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>33.3</td>\n",
       "      <td>33.3</td>\n",
       "      <td>50.0</td>\n",
       "      <td>41.7</td>\n",
       "      <td>-7.1</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tao Xu</td>\n",
       "      <td>Center</td>\n",
       "      <td>73.0</td>\n",
       "      <td>277</td>\n",
       "      <td>Haverford School (PA)</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>42.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.7</td>\n",
       "      <td>42.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       player_name position  height(inches) weight(lbs)  \\\n",
       "0      Jeff Xavier    Guard            72.0         183   \n",
       "1  Ioannis Xenakis   Center            84.0         213   \n",
       "2        Aaron Xia  Forward            80.0         203   \n",
       "3         Ji Xiang  Forward            73.0         208   \n",
       "4        Oliver Xu    Guard            74.0         170   \n",
       "5           Tao Xu   Center            73.0         277   \n",
       "\n",
       "                      high_school                   college  draft_year  \\\n",
       "0                            None  Manhattan and Providence        2009   \n",
       "1                            None                  Delaware        2003   \n",
       "2                            None                   Citadel        2006   \n",
       "3                            None                    Hawaii        2010   \n",
       "4  Hong Kong International School                      Rice        2016   \n",
       "5           Haverford School (PA)             San Francisco        2014   \n",
       "\n",
       "   years_in_college  games  points  rebounds  assists  fg_percent  \\\n",
       "0                 4  124.0    11.5       3.8      1.8        40.8   \n",
       "1                 2   24.0     2.6       0.9      0.0        44.4   \n",
       "2                 3   73.0     2.6       2.1      0.1        45.7   \n",
       "3                 2   28.0     1.4       1.2      0.1        40.9   \n",
       "4                 1   11.0     0.5       0.2      0.1        33.3   \n",
       "5                 2   36.0     2.6       1.1      0.2        42.5   \n",
       "\n",
       "   3_fg_percent  free_throw_percent  effective_fg_percent  \\\n",
       "0          34.2                78.8                  51.5   \n",
       "1           NaN                43.8                  44.4   \n",
       "2          30.8                69.2                  47.0   \n",
       "3           0.0                55.6                  40.9   \n",
       "4          33.3                50.0                  41.7   \n",
       "5           NaN                66.7                  42.5   \n",
       "\n",
       "   player_efficiency_rating  win_shares  \n",
       "0                       NaN         9.5  \n",
       "1                       NaN         0.1  \n",
       "2                       NaN         1.4  \n",
       "3                       NaN         0.3  \n",
       "4                      -7.1        -0.1  \n",
       "5                       2.1        -0.2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "player_page = SoupFromURL(str(url))\n",
    "\n",
    "#player profile info\n",
    "a = player_page.find_all('div', attrs={'class':'nothumb'})[0]\n",
    "a_soup = BeautifulSoup(str(a),\"html5lib\")\n",
    "a = player_page.find_all('div', attrs={'class':'nothumb'})[0]\n",
    "\n",
    "try:\n",
    "    n = str(a_soup.text.split('\\n')[1])\n",
    "    name = n.replace(\"\\t\",\"\")\n",
    "except:\n",
    "    name = None\n",
    "\n",
    "try:\n",
    "    p = str(a_soup.text.split('\\n')[13])\n",
    "    position = p.replace(\"  \",\"\")\n",
    "except:\n",
    "    position = None\n",
    "\n",
    "try:\n",
    "    ft = float(str(a_soup.text.split('\\n')[17])[2])*12\n",
    "    inch = float(str(a_soup.text.split('\\n')[17])[4])\n",
    "    height = ft+inch\n",
    "except:\n",
    "    height = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below to troubleshoot college column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "player_page = SoupFromURL('https://www.sports-reference.com/cbb/players/jordan-aaberg-1.html')\n",
    "    \n",
    "a = player_page.find_all('div', attrs={'class':'nothumb'})[0]\n",
    "a_soup = BeautifulSoup(str(a),\"html5lib\")\n",
    "\n",
    "\n",
    "col_list = []\n",
    "try:\n",
    "    c_4 = str(a_soup.text.split('\\n')[18])\n",
    "    college_4 = c_4.replace(\"  School: \",\"\")\n",
    "    college_4 = college_4.replace(\"  Schools: \",\"\")\n",
    "    col_list.append(college_4)\n",
    "    \n",
    "    c = str(a_soup.text.split('\\n')[28])\n",
    "    college = c.replace(\"  School: \",\"\")\n",
    "    college = college.replace(\"  Schools: \",\"\")\n",
    "    col_list.append(college)\n",
    "    \n",
    "    c_2 = str(a_soup.text.split('\\n')[32])\n",
    "    college_2 = c_2.replace(\"  School: \",\"\")\n",
    "    college_2 = college_2.replace(\"  Schools: \",\"\")\n",
    "    col_list.append(college_2)\n",
    "    \n",
    "    c_3 = str(a_soup.text.split('\\n')[24])\n",
    "    college_3 = c_3.replace(\"  School: \",\"\")\n",
    "    college_3 = college_3.replace(\"  Schools: \",\"\")\n",
    "    col_list.append(college_3)\n",
    "\n",
    "        #final_college = list(filter(None, col_list))\n",
    "        #final_college.append(None)\n",
    "    col_list = [x for x in col_list if not '  ' in x]\n",
    "    col_list.append(None)\n",
    "except:\n",
    "    col_list.append(None)\n",
    "\n",
    "while '' in col_list:\n",
    "    col_list.remove('')\n",
    "    \n",
    "col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "player_page = SoupFromURL('https://www.sports-reference.com/cbb/players/_-ziegenhorn-1.html')\n",
    "\n",
    "col_list_2 = []\n",
    "a = player_page.find_all('div', attrs={'class':'nothumb'})[0]\n",
    "a_soup = BeautifulSoup(str(a),\"html5lib\")\n",
    "\n",
    "col_5 = str(a_soup.text.split('\\n')[18])\n",
    "\n",
    "col_list_2.append(col_5)\n",
    "\n",
    "col_list_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
